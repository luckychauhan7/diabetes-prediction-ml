# diabetes-prediction-ml
Machine learning project for diabetes risk prediction using Random Forest

--A complete ML pipeline for diabetes risk prediction on the Pima Indians Diabetes dataset featuring a Random Forest classifier, standardized preprocessing, reproducible training/evaluation, a CLI predictor for oneâ€‘off inputs, and a Streamlit dashboard for data exploration and realâ€‘time inference; intended for learning and baseline benchmarking, not for clinical use. --



Overview

Goal: Predict diabetes onset from 8 features in the Pima Indians Diabetes dataset and surface an interpretable risk score for decision support ğŸ©ºğŸ“Š.

Approach: Train/test split with standardized features, Random Forest classification, model persistence (Joblib), and simple deployment surfaces (CLI + Streamlit) for fast experimentation and use âš™ï¸ğŸ§ª.

Outcome: Baseline accuracy in the 75â€“80% range on heldâ€‘out data, with probability outputs to communicate riskâ€”consistent with common educational baselines reported across community tutorials âœ….

Key features

ğŸŒ² Random Forest with 100 trees and calibratedâ€‘style probability outputs via predict_proba for friendly risk communication.

ğŸ§° Endâ€‘toâ€‘end scripts: training, artifact saving, and a CLI for singleâ€‘sample predictionsâ€”great for quick checks and automation.

ğŸ–¥ï¸ Streamlit app: dataset overview, feature distributions, correlations, and onâ€‘page predictions in a clean UI for nonâ€‘technical stakeholders.

Dataset

Source: Pima Indians Diabetes Database (768 rows; 8 predictors + Outcome), a widely used benchmark; patients are adult females of Pima Indian heritage ğŸ“š.

Features: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age; target Outcome âˆˆ {0,1} ğŸ§¾.

Project structure

Training: Read CSV, scale features with StandardScaler, split train/test, fit Random Forest, and report accuracy, confusion matrix, and classification reportâ€”then save model/scaler with Joblib ğŸ§ª.

Prediction (CLI): Load artifacts, accept typed inputs, apply the same scaling, and return class label plus probability ğŸ”.

Streamlit app: Load data and artifacts, show dataset stats, histograms, and a correlation heatmap, then generate instant predictions from inputs ğŸ›ï¸.

How to run

Install deps and ensure diabetes.csv is availableâ€”or pull the canonical CSV URL used across community examples ğŸ“¥.

Train: python train_model.py to produce diabetes_prediction_model.pkl and scaler.pkl in the project root ğŸ§±.

Predict (CLI): python predict_cli.py to enter values interactively and view label + probability in the terminal â–¶ï¸.

Launch app: streamlit run Diabetes-Prediction-by-Lucky-Chauhan.py to explore data and make onâ€‘page predictions ğŸŒ.

Modeling notes

Why Random Forest: strong tabular baseline, resilient to nonâ€‘linearities and feature interactions, and easy to interpret via feature importance ğŸŒ².

Typical baselines: community work on this dataset often lands midâ€‘70s to midâ€‘80s without heavy tuning; gains come from better imputation, class weighting, and hyperparameter search ğŸ¯.

Limitations

Educational use only: small dataset with known quirks (e.g., zeros in physiological fields), so predictions are not clinical advice ğŸ§ªğŸš«.

Cohort constraints: trained on adult Pima Indian females; broader use requires retraining and validation on representative populations ğŸŒ.

Roadmap

ğŸ” Add crossâ€‘validation and RandomizedSearchCV to tighten performance bounds and reduce variance.

ğŸ¯ Calibrate probabilities (Platt/Isotonic) to improve risk communication, especially in the UI.

ğŸª„ Add explainability (feature importances/SHAP) inside the Streamlit app for transparency and trust.

References

Pima Indians Diabetes Database overview and canonical CSV access ğŸ”—.

Comparable Random Forest and Streamlit implementations for diabetes prediction and demo apps ğŸ“.
